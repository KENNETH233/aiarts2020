{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,train_labels),(test_images,test_labels) = cifar10.load_data()\n",
    "train_images.shape, test_images.shape\n",
    "train_images = train_images/255.0\n",
    "test_images = test_images/255.0\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deer'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 180\n",
    "plt.imshow(train_images[index])\n",
    "class_names[int(train_labels[index]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /opt/anaconda3/envs/plaidml-keras/lib/python3.8/site-packages (7.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/plaidml-keras/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2812\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2813\u001b[0;31m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2814\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7b4d0461579c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# load the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# convert to numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/plaidml-keras/lib/python3.8/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/plaidml-keras/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2813\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2815\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2816\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load the image\n",
    "img = load_img(train_images)\n",
    "# convert to numpy array\n",
    "data = img_to_array(train_images[index])\n",
    "# expand dimension to one sample\n",
    "samples = expand_dims(data, 0)\n",
    "# create image data augmentation generator\n",
    "datagen = ImageDataGenerator(height_shift_range=0.5)\n",
    "# prepare iterator\n",
    "it = datagen.flow(samples, batch_size=1)\n",
    "# generate samples and plot\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# generate batch of images\n",
    "\tbatch = it.next()\n",
    "\t# convert to unsigned integers for viewing\n",
    "\timage = batch[0].astype('uint8')\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images/255.0\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape = (32,32,3)),\n",
    "    Dense(128, activation = \"relu\"),\n",
    "    Dense(10,activation = \"softmax\")\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = \"Adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 2.0357 - acc: 0.2696\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.8830 - acc: 0.3329\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.8276 - acc: 0.3536\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.7840 - acc: 0.3692\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.7485 - acc: 0.3799\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.7179 - acc: 0.3946\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.6896 - acc: 0.4048\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.6649 - acc: 0.4120\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.6427 - acc: 0.4216\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.6236 - acc: 0.4289\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.6063 - acc: 0.4352\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.5917 - acc: 0.4406\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.5775 - acc: 0.4464\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.5661 - acc: 0.4506\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.5559 - acc: 0.4533\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5465 - acc: 0.4567\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.5357 - acc: 0.4606\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.5276 - acc: 0.4631\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.5195 - acc: 0.4664\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.5114 - acc: 0.4684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x135b55e50>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images,train_labels, epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.evaluate(test_iamges,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 394,634\n",
      "Trainable params: 394,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
